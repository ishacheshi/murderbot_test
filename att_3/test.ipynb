{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2e166a39-4e87-4a09-bc26-65b2e68fa887",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import asyncio\n",
    "import json\n",
    "from playwright.async_api import async_playwright, TimeoutError as PlaywrightTimeout\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d2826243-d26d-4140-abae-67f671d0880e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SESSION_FILE = \"goodreads_session.json\"\n",
    "\n",
    "\n",
    "async def save_session():\n",
    "    async with async_playwright() as p:\n",
    "        browser = await p.chromium.launch(headless=False)\n",
    "\n",
    "        context = await browser.new_context(\n",
    "            viewport={\"width\": 1280, \"height\": 800}\n",
    "        )\n",
    "        page = await context.new_page()\n",
    "\n",
    "        # Go to Goodreads login page\n",
    "        await page.goto(\"https://www.goodreads.com/user/sign_in\")\n",
    "\n",
    "        print(\"\\nðŸš¨ MANUAL LOGIN REQUIRED ðŸš¨\")\n",
    "        print(\"1) Log in to Goodreads in the browser\")\n",
    "        print(\"2) Make sure you are fully logged in\")\n",
    "        print(\"3) You may see a CAPTCHA â€” solve it\")\n",
    "        input(\"ðŸ‘‰ Press Enter AFTER login is complete...\")\n",
    "\n",
    "        # Save cookies + local storage\n",
    "        await context.storage_state(path=SESSION_FILE)\n",
    "        print(f\"âœ… Session saved to {SESSION_FILE}\")\n",
    "\n",
    "        await browser.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "19c26992-e2ef-4b97-9725-06218624b4a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸš¨ MANUAL LOGIN REQUIRED ðŸš¨\n",
      "1) Log in to Goodreads in the browser\n",
      "2) Make sure you are fully logged in\n",
      "3) You may see a CAPTCHA â€” solve it\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ðŸ‘‰ Press Enter AFTER login is complete... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Session saved to goodreads_session.json\n"
     ]
    }
   ],
   "source": [
    "await save_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "504deb5d-7eb8-4f8a-8f53-56f3de1494ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "from playwright.async_api import async_playwright\n",
    "from dateutil import parser as dateparser\n",
    "\n",
    "START_URL = \"https://www.goodreads.com/book/show/32758901-all-systems-red/reviews\"\n",
    "CHECKPOINT_FILE = \"goodreads_reviews_checkpoint.jsonl\"\n",
    "\n",
    "# --------------------------------\n",
    "# Utilities\n",
    "# --------------------------------\n",
    "\n",
    "def normalize_date(date_str):\n",
    "    if not date_str:\n",
    "        return None\n",
    "    try:\n",
    "        return dateparser.parse(date_str).date().isoformat()\n",
    "    except:\n",
    "        return date_str.strip()\n",
    "\n",
    "\n",
    "def review_signature(r):\n",
    "    return (\n",
    "        (r.get(\"username\") or \"\").lower().strip(),\n",
    "        (r.get(\"date\") or \"\").strip(),\n",
    "        r.get(\"text\", \"\")[:200].lower()\n",
    "    )\n",
    "\n",
    "\n",
    "def load_existing_signatures():\n",
    "    seen = set()\n",
    "    if os.path.exists(CHECKPOINT_FILE):\n",
    "        with open(CHECKPOINT_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                r = json.loads(line)\n",
    "                seen.add(review_signature(r))\n",
    "    return seen\n",
    "\n",
    "\n",
    "def append_checkpoint(reviews):\n",
    "    with open(CHECKPOINT_FILE, \"a\", encoding=\"utf-8\") as f:\n",
    "        for r in reviews:\n",
    "            f.write(json.dumps(r, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "\n",
    "# --------------------------------\n",
    "# Page interaction helpers\n",
    "# --------------------------------\n",
    "\n",
    "async def expand_review_text(page):\n",
    "    expanders = await page.query_selector_all(\n",
    "        \"article a:has-text('Show more'), article button:has-text('Show more')\"\n",
    "    )\n",
    "    for el in expanders:\n",
    "        try:\n",
    "            await page.evaluate(\"(e) => e.click()\", el)\n",
    "            await page.wait_for_timeout(120)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "async def extract_current_reviews(page):\n",
    "    return await page.eval_on_selector_all(\n",
    "        \"article, div[data-testid='review']\",\n",
    "        r\"\"\"\n",
    "        cards => cards.map(card => {\n",
    "            const username =\n",
    "                card.querySelector('a[href*=\"/user/show\"]')?.innerText?.trim() ?? null;\n",
    "\n",
    "            let date = null;\n",
    "            const spans = Array.from(card.querySelectorAll('span'))\n",
    "                .map(s => s.innerText.trim())\n",
    "                .filter(t =>\n",
    "                    t.match(/\\d{4}|ago|Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec/)\n",
    "                );\n",
    "\n",
    "            if (spans.length > 0) {\n",
    "                date = spans[spans.length - 1];\n",
    "            }\n",
    "\n",
    "            return {\n",
    "                username,\n",
    "                date,\n",
    "                text: card.innerText.trim()\n",
    "            };\n",
    "        })\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "\n",
    "async def find_page_level_load_more(page):\n",
    "    buttons = await page.query_selector_all(\"button:has-text('Show more')\")\n",
    "    for btn in buttons:\n",
    "        inside_review = await btn.evaluate(\n",
    "            \"el => el.closest('article, div[data-testid=\\\"review\\\"]') !== null\"\n",
    "        )\n",
    "        if not inside_review:\n",
    "            return btn\n",
    "    return None\n",
    "\n",
    "\n",
    "# --------------------------------\n",
    "# Main scraper\n",
    "# --------------------------------\n",
    "\n",
    "async def scrape_goodreads_reviews(\n",
    "    max_pages=5000,\n",
    "    manual_unlock=True\n",
    "):\n",
    "    seen_reviews = load_existing_signatures()\n",
    "    print(f\"Resuming with {len(seen_reviews)} reviews already saved\")\n",
    "\n",
    "    async with async_playwright() as p:\n",
    "        browser = await p.chromium.launch(headless=False)\n",
    "\n",
    "        # ðŸ”‘ SHORT viewport is REQUIRED\n",
    "        context = await browser.new_context(\n",
    "            viewport={\"width\": 1280, \"height\": 700}\n",
    "        )\n",
    "        page = await context.new_page()\n",
    "\n",
    "        await page.goto(START_URL, wait_until=\"domcontentloaded\")\n",
    "        await page.wait_for_timeout(4000)\n",
    "\n",
    "        # --------------------------------\n",
    "        # Manual unlock (ONCE)\n",
    "        # --------------------------------\n",
    "        if manual_unlock:\n",
    "            print(\"\\nðŸš¨ MANUAL STEP (ONCE PER SESSION) ðŸš¨\")\n",
    "            print(\"â€¢ Scroll normally\")\n",
    "            print(\"â€¢ Click 'Show more reviews' ONCE\")\n",
    "            print(\"â€¢ Confirm reviews change\")\n",
    "            input(\"ðŸ‘‰ Press Enter to continue automation...\")\n",
    "\n",
    "        # --------------------------------\n",
    "        # Pagination loop (replace model)\n",
    "        # --------------------------------\n",
    "        for page_num in range(max_pages):\n",
    "            print(f\"\\n--- Review batch {page_num + 1} ---\")\n",
    "\n",
    "            # Expand review-level text first\n",
    "            await expand_review_text(page)\n",
    "\n",
    "            current_reviews = await extract_current_reviews(page)\n",
    "            if not current_reviews:\n",
    "                print(\"No reviews found. Stopping.\")\n",
    "                break\n",
    "\n",
    "            new_reviews = []\n",
    "            for r in current_reviews:\n",
    "                r[\"date\"] = normalize_date(r[\"date\"])\n",
    "                sig = review_signature(r)\n",
    "                if sig not in seen_reviews:\n",
    "                    seen_reviews.add(sig)\n",
    "                    new_reviews.append(r)\n",
    "\n",
    "            if new_reviews:\n",
    "                append_checkpoint(new_reviews)\n",
    "                print(\n",
    "                    f\"Saved {len(new_reviews)} new reviews \"\n",
    "                    f\"(total saved: {len(seen_reviews)})\"\n",
    "                )\n",
    "            else:\n",
    "                print(\"No new reviews on this page\")\n",
    "\n",
    "            load_more = await find_page_level_load_more(page)\n",
    "            if not load_more:\n",
    "                print(\"No 'Show more reviews' button found. Done.\")\n",
    "                break\n",
    "\n",
    "            before_text = current_reviews[0][\"text\"]\n",
    "\n",
    "            await load_more.scroll_into_view_if_needed()\n",
    "            await page.wait_for_timeout(500)\n",
    "            await page.evaluate(\"(b) => b.click()\", load_more)\n",
    "\n",
    "            # Polite delay (human-like)\n",
    "            await page.wait_for_timeout(random.randint(1200, 2200))\n",
    "\n",
    "            after_reviews = await extract_current_reviews(page)\n",
    "            if after_reviews and after_reviews[0][\"text\"] == before_text:\n",
    "                print(\"Page content did not change. Stopping.\")\n",
    "                break\n",
    "\n",
    "        await browser.close()\n",
    "\n",
    "\n",
    "# --------------------------------\n",
    "# Run\n",
    "# --------------------------------\n",
    "\n",
    "# Start small first (e.g., max_pages=5), then increase to ~5000\n",
    "# reviews â‰ˆ 10 per page after first page\n",
    "#\n",
    "# await scrape_goodreads_reviews(max_pages=5000, manual_unlock=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3d16695a-b15a-4c00-9596-5c82e863d602",
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm ./goodreads_reviews_checkpoint.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a950dfe2-222c-43d1-ade2-5779ded12706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming with 0 reviews already saved\n",
      "\n",
      "--- Review batch 1 ---\n",
      "Saved 31 new reviews (total saved: 31)\n",
      "\n",
      "--- Review batch 2 ---\n",
      "Saved 30 new reviews (total saved: 61)\n",
      "\n",
      "--- Review batch 3 ---\n",
      "Saved 30 new reviews (total saved: 91)\n",
      "\n",
      "--- Review batch 4 ---\n",
      "Saved 30 new reviews (total saved: 121)\n",
      "\n",
      "--- Review batch 5 ---\n",
      "Saved 30 new reviews (total saved: 151)\n",
      "\n",
      "--- Review batch 6 ---\n",
      "Saved 30 new reviews (total saved: 181)\n",
      "\n",
      "--- Review batch 7 ---\n",
      "Saved 30 new reviews (total saved: 211)\n",
      "\n",
      "--- Review batch 8 ---\n",
      "Saved 30 new reviews (total saved: 241)\n",
      "\n",
      "--- Review batch 9 ---\n",
      "Saved 30 new reviews (total saved: 271)\n",
      "\n",
      "--- Review batch 10 ---\n",
      "Saved 30 new reviews (total saved: 301)\n",
      "\n",
      "--- Review batch 11 ---\n",
      "Saved 30 new reviews (total saved: 331)\n",
      "\n",
      "--- Review batch 12 ---\n",
      "Saved 30 new reviews (total saved: 361)\n",
      "\n",
      "--- Review batch 13 ---\n",
      "Saved 30 new reviews (total saved: 391)\n",
      "\n",
      "--- Review batch 14 ---\n",
      "Saved 30 new reviews (total saved: 421)\n",
      "\n",
      "--- Review batch 15 ---\n",
      "Saved 30 new reviews (total saved: 451)\n",
      "\n",
      "--- Review batch 16 ---\n",
      "Saved 30 new reviews (total saved: 481)\n",
      "\n",
      "--- Review batch 17 ---\n",
      "Saved 30 new reviews (total saved: 511)\n",
      "\n",
      "--- Review batch 18 ---\n",
      "Saved 30 new reviews (total saved: 541)\n",
      "\n",
      "--- Review batch 19 ---\n",
      "Saved 30 new reviews (total saved: 571)\n",
      "\n",
      "--- Review batch 20 ---\n",
      "Saved 30 new reviews (total saved: 601)\n",
      "\n",
      "--- Review batch 21 ---\n",
      "Saved 30 new reviews (total saved: 631)\n",
      "\n",
      "--- Review batch 22 ---\n",
      "Saved 30 new reviews (total saved: 661)\n",
      "\n",
      "--- Review batch 23 ---\n",
      "Saved 30 new reviews (total saved: 691)\n",
      "\n",
      "--- Review batch 24 ---\n",
      "Saved 30 new reviews (total saved: 721)\n",
      "\n",
      "--- Review batch 25 ---\n",
      "Saved 30 new reviews (total saved: 751)\n",
      "\n",
      "--- Review batch 26 ---\n",
      "Saved 30 new reviews (total saved: 781)\n",
      "\n",
      "--- Review batch 27 ---\n",
      "Saved 30 new reviews (total saved: 811)\n",
      "\n",
      "--- Review batch 28 ---\n",
      "Saved 30 new reviews (total saved: 841)\n",
      "\n",
      "--- Review batch 29 ---\n",
      "Saved 30 new reviews (total saved: 871)\n",
      "\n",
      "--- Review batch 30 ---\n",
      "Saved 30 new reviews (total saved: 901)\n",
      "\n",
      "--- Review batch 31 ---\n",
      "Saved 30 new reviews (total saved: 931)\n",
      "\n",
      "--- Review batch 32 ---\n",
      "Saved 30 new reviews (total saved: 961)\n",
      "\n",
      "--- Review batch 33 ---\n",
      "Saved 30 new reviews (total saved: 991)\n",
      "\n",
      "--- Review batch 34 ---\n",
      "Saved 30 new reviews (total saved: 1021)\n",
      "\n",
      "--- Review batch 35 ---\n",
      "Saved 30 new reviews (total saved: 1051)\n",
      "\n",
      "--- Review batch 36 ---\n",
      "Saved 30 new reviews (total saved: 1081)\n",
      "\n",
      "--- Review batch 37 ---\n",
      "Saved 30 new reviews (total saved: 1111)\n",
      "\n",
      "--- Review batch 38 ---\n",
      "Saved 30 new reviews (total saved: 1141)\n",
      "\n",
      "--- Review batch 39 ---\n",
      "Saved 30 new reviews (total saved: 1171)\n",
      "\n",
      "--- Review batch 40 ---\n",
      "Saved 30 new reviews (total saved: 1201)\n",
      "\n",
      "--- Review batch 41 ---\n",
      "Saved 30 new reviews (total saved: 1231)\n",
      "\n",
      "--- Review batch 42 ---\n",
      "Saved 30 new reviews (total saved: 1261)\n",
      "\n",
      "--- Review batch 43 ---\n",
      "Saved 30 new reviews (total saved: 1291)\n",
      "\n",
      "--- Review batch 44 ---\n",
      "Saved 30 new reviews (total saved: 1321)\n",
      "\n",
      "--- Review batch 45 ---\n",
      "Saved 30 new reviews (total saved: 1351)\n",
      "\n",
      "--- Review batch 46 ---\n",
      "Saved 30 new reviews (total saved: 1381)\n",
      "\n",
      "--- Review batch 47 ---\n",
      "Saved 30 new reviews (total saved: 1411)\n",
      "\n",
      "--- Review batch 48 ---\n",
      "Saved 30 new reviews (total saved: 1441)\n",
      "\n",
      "--- Review batch 49 ---\n",
      "Saved 30 new reviews (total saved: 1471)\n",
      "\n",
      "--- Review batch 50 ---\n",
      "Saved 30 new reviews (total saved: 1501)\n",
      "\n",
      "--- Review batch 51 ---\n",
      "Saved 30 new reviews (total saved: 1531)\n",
      "\n",
      "--- Review batch 52 ---\n",
      "Saved 30 new reviews (total saved: 1561)\n",
      "\n",
      "--- Review batch 53 ---\n",
      "Saved 30 new reviews (total saved: 1591)\n",
      "\n",
      "--- Review batch 54 ---\n",
      "Saved 30 new reviews (total saved: 1621)\n",
      "\n",
      "--- Review batch 55 ---\n",
      "Saved 30 new reviews (total saved: 1651)\n",
      "\n",
      "--- Review batch 56 ---\n",
      "Saved 30 new reviews (total saved: 1681)\n",
      "\n",
      "--- Review batch 57 ---\n",
      "Saved 30 new reviews (total saved: 1711)\n",
      "\n",
      "--- Review batch 58 ---\n",
      "Saved 30 new reviews (total saved: 1741)\n",
      "\n",
      "--- Review batch 59 ---\n",
      "Saved 30 new reviews (total saved: 1771)\n",
      "\n",
      "--- Review batch 60 ---\n",
      "Saved 30 new reviews (total saved: 1801)\n",
      "Page content did not change. Stopping.\n"
     ]
    }
   ],
   "source": [
    "await scrape_goodreads_reviews(max_pages=5000, manual_unlock=False) # manual_unlock=True GPT says should be False when logged in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "09436757-80fe-4f2c-8304-02980860bd8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'username': '', 'date': '2017-08-29', 'text': 'K.J. Charles\\nAuthor\\xa0\\n65 books\\n12.1k followers\\nFollow\\nRead\\nAugust 29, 2017\\nMagnificent. Tor.com continue to rock it with this fantastic tale of a self-hacked cyborg security unit with a gloriously bad attitude. It just wants to sit there downloading soaps but HEY HO SABOTAGE, PEOPLE TO SAVE, PEOPLE TO KILL.\\n\\nTerrific writing, lovely characterisation, very funny, and there will be more! Consider me glued.\\nfun-fun-fun\\n \\nnovella\\n \\noh-god-where-is-the-next-book\\n \\n...more\\n128 likes\\n3 comments\\nLike\\nComment'}\n",
      "{'username': '', 'date': 'read-in-2019', 'text': \"Melanie (meltotheany)\\n1,195 reviews\\n102k followers\\nFollow\\nAugust 23, 2019\\nI really enjoyed this! And it had such a great discussion on what it means to be human and what we are all willing to do in the name of trust. I can't wait to continue on with this series! <3\\n\\nBlog | Instagram | Twitter | Tumblr | Youtube | Twitch\\n\\nBuddy read with Lea! â¤\\n\\nâ¤ I read this for The Reading Rush, 2019!\\nadult\\n \\nbuddy-reads\\n \\nread-in-2019\\n \\n...more\\n125 likes\\nLike\\nComment\"}\n",
      "{'username': '', 'date': '2018-02-26', 'text': 'Alice\\n229 reviews\\n49 followers\\nFollow\\nFebruary 26, 2018\\n0.25* dnf: 27% It\\'s only 144 pages too that\\'s how shit it is.\\nTHIS BOOK IS ABSOLUTE SHIT I JUST WANT TO MAKE THAT VERY CLEAR. THE WRITING IS MEDIOCRE SHIT TOO.\\n\\nBarely any description about what the technology actually looks like. There is also no description on the settings either. There were other things I hated, but the story having no description was the worst part.\\n\\nThe main character is a murderbot that has social anxiety. It\\'s not done in a relatable way at all. \"Omg they hate me because I\\'m a robot\". It\\'s just said over and over again that the main character feels awkward around humans.\\n\\nLater on the story points out that since the main character is a robot it has no gender and doesn\\'t care about sex. Again there\\'s a whole paragraph on this and it doesn\\'t feel naturally integrated into the story at all. \"Look I\\'m trying to be diverse\". Yeah it\\'s a robot of course it doesn\\'t have to have a gender. Another thing is that the main character reads actually like a girl so this whole gender neutral thing is not working out. I\\'m not actually sure what a murderbot is yet, but I\\'m not reading the whole thing to find out.\\n1-star\\n \\ndnf\\n119 likes\\n22 comments\\nLike\\nComment'}\n",
      "{'username': '', 'date': '*Edited to add*\\nI met Martha Wells today!!\\n\\n\\nI\\'m on the left. Yes, my hair is lavender.\\nI am finally starting a blog. It is about time, yeah? Only a thousand reviews to add onto that site. www.jillyshmilly.blogspot.com\\n\\nThis book takes several pages to get acclimated, and also to get some understanding of our narrator. He (I\\'m using \"he\" although Murderbot doesn\\'t have a gender) is part human/part robot and is really very much like April Ludgate on Parks and Rec, or maybe a honey badger, because Murderbot just don\\'t give a shit.\\n\\n\\n\\n\\nMurderbot must also be American, and possibly a teenager because he also does the bare minimum possible when it comes to his job.\\n\\n...all they had was Murderbot, who just wanted everyone to shut up and leave it alone so it could watch the entertainment feed all day..\\n\\nIf by \"entertainment feed\", it means that it wants to hang out on the internet when it\\'s not reading or binge-watching Netflix, I think they may have cloned me to make Murderbot. I sure as hell approve of his hobbies, and his name. He chose his own name. It\\'s catchy, I like it.\\n\\n\\n\\nHehe! Oh, you!\\n\\nUnfortunately for Murderbot, someone is trying to kill the humans that he\\'s supposed to protect in between soap opera episodes. That sucks.\\n\\nI\\'ve got four perfectly good humans here and I didn\\'t want them to get killed...it would look bad on my record, and my record was already pretty terrible.\\n\\nPriorities, you know. Permanent records are permanent.\\n\\n\\n\\n\\nSo, Murderbot has to do some work, and he has to interact with humans - his two least favorite activities.\\n\\n\\n\\n\\nThis story was short, but funny if you love depressed robots with low self-esteem.', 'text': 'Jilly\\n1,838 reviews\\n6,684 followers\\nFollow\\nMay 13, 2018\\n*Edited to add*\\nI met Martha Wells today!!\\n\\n\\nI\\'m on the left. Yes, my hair is lavender.\\nI am finally starting a blog. It is about time, yeah? Only a thousand reviews to add onto that site. www.jillyshmilly.blogspot.com\\n\\nThis book takes several pages to get acclimated, and also to get some understanding of our narrator. He (I\\'m using \"he\" although Murderbot doesn\\'t have a gender) is part human/part robot and is really very much like April Ludgate on Parks and Rec, or maybe a honey badger, because Murderbot just don\\'t give a shit.\\n\\n\\n\\n\\nMurderbot must also be American, and possibly a teenager because he also does the bare minimum possible when it comes to his job.\\n\\n...all they had was Murderbot, who just wanted everyone to shut up and leave it alone so it could watch the entertainment feed all day..\\n\\nIf by \"entertainment feed\", it means that it wants to hang out on the internet when it\\'s not reading or binge-watching Netflix, I think they may have cloned me to make Murderbot. I sure as hell approve of his hobbies, and his name. He chose his own name. It\\'s catchy, I like it.\\n\\n\\n\\nHehe! Oh, you!\\n\\nUnfortunately for Murderbot, someone is trying to kill the humans that he\\'s supposed to protect in between soap opera episodes. That sucks.\\n\\nI\\'ve got four perfectly good humans here and I didn\\'t want them to get killed...it would look bad on my record, and my record was already pretty terrible.\\n\\nPriorities, you know. Permanent records are permanent.\\n\\n\\n\\n\\nSo, Murderbot has to do some work, and he has to interact with humans - his two least favorite activities.\\n\\n\\n\\n\\nThis story was short, but funny if you love depressed robots with low self-esteem.\\n\\n\\nnovella\\n \\nsci-fi\\n122 likes\\n28 comments\\nLike\\nComment'}\n",
      "{'username': '', 'date': \"Loved this book, it's a four point five and would've been a full five except for the ending.\\nFor me, great scifi is when the author doesn't start out telling me how this new world works. I'm far more interested in how the characters act/behave/ survive in this world that is unfamiliar to me. Good scifi hits the ground running giving the reader enough credit to keep up as the author slowly metes out the world building while setting a very dynamic conflict.\\nMy favorite scifi of late is Old Man's War, what a great read (along with the two followups). All systems Red is on this same level for me. The story starts off at a run and doesn't let up until the end. I loved it.\\nThe minor problem for me is that in normal story arcs there are four sections, conflict, complication, crisis, and conclusion. This book has the crisis and the conclusion it runs so hot at such a frenetic pace the whole book feels like the crisis in the arc. Because of this the final crisis fizzles or pales to some of the wonderful earlier action scenes. This also happened for me in the book, Passages. The scene on train in that book made the ending feel like a fizzle. But oh, was that train scene something else.\\nDoesn't matter though, I picked all the other Martha Wells books. She can really write a strong female character that is viewed through the eyes of a murderbot.\\nDavid Putnam author of the Bruno Johnson series.\", 'text': \"David Putnam\\nAuthor\\xa0\\n20 books\\n2,027 followers\\nFollow\\nJune 4, 2020\\nLoved this book, it's a four point five and would've been a full five except for the ending.\\nFor me, great scifi is when the author doesn't start out telling me how this new world works. I'm far more interested in how the characters act/behave/ survive in this world that is unfamiliar to me. Good scifi hits the ground running giving the reader enough credit to keep up as the author slowly metes out the world building while setting a very dynamic conflict.\\nMy favorite scifi of late is Old Man's War, what a great read (along with the two followups). All systems Red is on this same level for me. The story starts off at a run and doesn't let up until the end. I loved it.\\nThe minor problem for me is that in normal story arcs there are four sections, conflict, complication, crisis, and conclusion. This book has the crisis and the conclusion it runs so hot at such a frenetic pace the whole book feels like the crisis in the arc. Because of this the final crisis fizzles or pales to some of the wonderful earlier action scenes. This also happened for me in the book, Passages. The scene on train in that book made the ending feel like a fizzle. But oh, was that train scene something else.\\nDoesn't matter though, I picked all the other Martha Wells books. She can really write a strong female character that is viewed through the eyes of a murderbot.\\nDavid Putnam author of the Bruno Johnson series.\\n122 likes\\n13 comments\\nLike\\nComment\"}\n"
     ]
    }
   ],
   "source": [
    "path = \"goodreads_reviews_checkpoint.jsonl\"\n",
    "\n",
    "with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "    for i, line in enumerate(f):\n",
    "        review = json.loads(line)\n",
    "        print(review)\n",
    "        if i == 4:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba98ef72-b501-4030-aa0b-8e757df4755c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"dates_151_goodreads_reviews.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(reviews, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0defa280-1205-47d7-a9b2-13b16c9b1781",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "20ef74b3-a141-4d46-8c3b-95e18570648e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b945301-d114-42d6-acf7-fc70b2956155",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e957e944-a162-481d-b30b-804a1ae8fff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact text duplicates: 0\n"
     ]
    }
   ],
   "source": [
    "texts = [r[\"text\"].strip() for r in reviews if r.get(\"text\")]\n",
    "text_counts = Counter(texts)\n",
    "\n",
    "exact_dupes = {t: c for t, c in text_counts.items() if c > 1}\n",
    "\n",
    "print(f\"Exact text duplicates: {len(exact_dupes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "501d0c28-178a-497e-9692-73b6cf4319c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, random\n",
    "from playwright.async_api import async_playwright\n",
    "from dateutil import parser as dateparser\n",
    "\n",
    "BASE_REVIEWS_URL = \"https://www.goodreads.com/book/show/32758901-all-systems-red/reviews\"\n",
    "SESSION_FILE = \"goodreads_session.json\"  # created by context.storage_state(...)\n",
    "\n",
    "def normalize_date(date_str):\n",
    "    if not date_str:\n",
    "        return None\n",
    "    try:\n",
    "        return dateparser.parse(date_str).date().isoformat()\n",
    "    except:\n",
    "        return date_str.strip()\n",
    "\n",
    "def review_signature(r):\n",
    "    return (\n",
    "        (r.get(\"username\") or \"\").lower().strip(),\n",
    "        (r.get(\"date\") or \"\").strip(),\n",
    "        (r.get(\"text\") or \"\")[:200].lower(),\n",
    "    )\n",
    "\n",
    "def load_existing_signatures(checkpoint_file):\n",
    "    seen = set()\n",
    "    if os.path.exists(checkpoint_file):\n",
    "        with open(checkpoint_file, \"r\", encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                r = json.loads(line)\n",
    "                seen.add(review_signature(r))\n",
    "    return seen\n",
    "\n",
    "def append_checkpoint(checkpoint_file, reviews):\n",
    "    with open(checkpoint_file, \"a\", encoding=\"utf-8\") as f:\n",
    "        for r in reviews:\n",
    "            f.write(json.dumps(r, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "async def expand_review_text(page):\n",
    "    expanders = await page.query_selector_all(\n",
    "        \"article a:has-text('Show more'), article button:has-text('Show more')\"\n",
    "    )\n",
    "    for el in expanders:\n",
    "        try:\n",
    "            await page.evaluate(\"(e) => e.click()\", el)\n",
    "            await page.wait_for_timeout(120)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "async def extract_current_reviews(page):\n",
    "    # Date extraction from metadata-ish spans (works better than <time> on this UI)\n",
    "    return await page.eval_on_selector_all(\n",
    "        \"article, div[data-testid='review']\",\n",
    "        r\"\"\"\n",
    "        cards => cards.map(card => {\n",
    "            const username =\n",
    "                card.querySelector('a[href*=\"/user/show\"]')?.innerText?.trim() ?? null;\n",
    "\n",
    "            let date = null;\n",
    "            const spans = Array.from(card.querySelectorAll('span'))\n",
    "                .map(s => s.innerText.trim())\n",
    "                .filter(t =>\n",
    "                    t.match(/\\d{4}|ago|Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec/)\n",
    "                );\n",
    "\n",
    "            if (spans.length > 0) date = spans[spans.length - 1];\n",
    "\n",
    "            return { username, date, text: card.innerText.trim() };\n",
    "        })\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "async def find_page_level_load_more(page):\n",
    "    # Page-level pagination control (exclude per-review expanders)\n",
    "    buttons = await page.query_selector_all(\"button:has-text('Show more')\")\n",
    "    for btn in buttons:\n",
    "        inside_review = await btn.evaluate(\n",
    "            \"el => el.closest('article, div[data-testid=\\\"review\\\"]') !== null\"\n",
    "        )\n",
    "        if not inside_review:\n",
    "            return btn\n",
    "    return None\n",
    "\n",
    "async def scrape_after_manual_sort(checkpoint_file, max_batches=5000):\n",
    "    \"\"\"\n",
    "    Opens Goodreads reviews page, waits for you to manually choose sort order,\n",
    "    then paginates and saves to checkpoint_file (JSONL).\n",
    "    \"\"\"\n",
    "    seen = load_existing_signatures(checkpoint_file)\n",
    "    print(f\"Resuming {checkpoint_file} with {len(seen)} reviews already saved\")\n",
    "\n",
    "    async with async_playwright() as p:\n",
    "        browser = await p.chromium.launch(headless=False)\n",
    "\n",
    "        # Short viewport so controls are reachable\n",
    "        context = await browser.new_context(\n",
    "            viewport={\"width\": 1280, \"height\": 700},\n",
    "            storage_state=SESSION_FILE,  # logged-in session\n",
    "        )\n",
    "        page = await context.new_page()\n",
    "\n",
    "        await page.goto(BASE_REVIEWS_URL, wait_until=\"domcontentloaded\")\n",
    "        await page.wait_for_timeout(3000)\n",
    "\n",
    "        # MANUAL SORT STEP\n",
    "        print(\"\\nðŸš¨ MANUAL STEP ðŸš¨\")\n",
    "        print(\"1) In the browser, set sort to the desired mode (Newest OR Oldest).\")\n",
    "        print(\"2) Wait until the visible reviews reorder.\")\n",
    "        input(\"ðŸ‘‰ Press Enter to start automated scraping...\")\n",
    "\n",
    "        # Optional: capture the post-sort URL (often same URL, but useful if it changes)\n",
    "        print(\"Current URL after your sort:\", page.url)\n",
    "\n",
    "        for batch in range(max_batches):\n",
    "            # Expand review text before extraction\n",
    "            await expand_review_text(page)\n",
    "\n",
    "            current = await extract_current_reviews(page)\n",
    "            if not current:\n",
    "                print(\"No reviews found; stopping.\")\n",
    "                break\n",
    "\n",
    "            # Collect & checkpoint new reviews\n",
    "            new_reviews = []\n",
    "            for r in current:\n",
    "                r[\"date\"] = normalize_date(r.get(\"date\"))\n",
    "                sig = review_signature(r)\n",
    "                if sig not in seen:\n",
    "                    seen.add(sig)\n",
    "                    new_reviews.append(r)\n",
    "\n",
    "            if new_reviews:\n",
    "                append_checkpoint(checkpoint_file, new_reviews)\n",
    "                print(f\"Batch {batch+1}: saved {len(new_reviews)} (total saved: {len(seen)})\")\n",
    "            else:\n",
    "                print(f\"Batch {batch+1}: no new reviews on this batch\")\n",
    "\n",
    "            # Click \"Show more reviews\" (page-level)\n",
    "            load_more = await find_page_level_load_more(page)\n",
    "            if not load_more:\n",
    "                print(\"No page-level 'Show more reviews' button found; done.\")\n",
    "                break\n",
    "\n",
    "            before_head = current[0][\"text\"][:200]\n",
    "\n",
    "            await load_more.scroll_into_view_if_needed()\n",
    "            await page.wait_for_timeout(400)\n",
    "            await page.evaluate(\"(b) => b.click()\", load_more)\n",
    "\n",
    "            # Polite delay\n",
    "            await page.wait_for_timeout(random.randint(1200, 2200))\n",
    "\n",
    "            after = await extract_current_reviews(page)\n",
    "            if after and after[0][\"text\"][:200] == before_head:\n",
    "                print(\"Page content did not change (hit window cap / end). Stopping.\")\n",
    "                break\n",
    "\n",
    "        await browser.close()\n",
    "\n",
    "# ---- Run newest then oldest (two manual runs) ----\n",
    "# 1) Run this, set sort to NEWEST manually, then press Enter\n",
    "# await scrape_after_manual_sort(\"reviews_newest.jsonl\", max_batches=5000)\n",
    "\n",
    "# 2) Run again, set sort to OLDEST manually, then press Enter\n",
    "# await scrape_after_manual_sort(\"reviews_oldest.jsonl\", max_batches=5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3c14fa1e-ffe6-4ca6-bb88-06deadf16540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming reviews_newest.jsonl with 0 reviews already saved\n",
      "\n",
      "ðŸš¨ MANUAL STEP ðŸš¨\n",
      "1) In the browser, set sort to the desired mode (Newest OR Oldest).\n",
      "2) Wait until the visible reviews reorder.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ðŸ‘‰ Press Enter to start automated scraping... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current URL after your sort: https://www.goodreads.com/book/show/32758901-all-systems-red/reviews\n",
      "Batch 1: saved 31 (total saved: 31)\n",
      "Batch 2: saved 30 (total saved: 61)\n",
      "Batch 3: saved 30 (total saved: 91)\n",
      "Batch 4: saved 30 (total saved: 121)\n",
      "Batch 5: saved 30 (total saved: 151)\n",
      "Batch 6: saved 30 (total saved: 181)\n",
      "Batch 7: saved 30 (total saved: 211)\n",
      "Batch 8: saved 30 (total saved: 241)\n",
      "Batch 9: saved 30 (total saved: 271)\n",
      "Batch 10: saved 30 (total saved: 301)\n",
      "Batch 11: saved 30 (total saved: 331)\n",
      "Batch 12: saved 30 (total saved: 361)\n",
      "Batch 13: saved 30 (total saved: 391)\n",
      "Batch 14: saved 30 (total saved: 421)\n",
      "Batch 15: saved 30 (total saved: 451)\n",
      "Batch 16: saved 30 (total saved: 481)\n",
      "Batch 17: saved 30 (total saved: 511)\n",
      "Batch 18: saved 30 (total saved: 541)\n",
      "Page content did not change (hit window cap / end). Stopping.\n"
     ]
    }
   ],
   "source": [
    "# choose newest, click show more, click enter.\n",
    "await scrape_after_manual_sort(\"reviews_newest.jsonl\", max_batches=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "662a8430-5844-4785-8996-c76e27006dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'username': '', 'date': '2025-12-21', 'text': 'katy â™¡\\n186 reviews\\nFollow\\nDecember 21, 2025\\ni loved this. murderbot is just so cutie and funny. i just think bc itâ€™s soo short that i ended up confused a bit. i needed this to be longer with more explanations. i think thatâ€™s just a skill issue tho. i know thereâ€™s 7 more books, so i will absolutely be reading those at some point\\n3 likes\\nLike\\nComment'}\n",
      "{'username': '', 'date': '2025-12-21', 'text': 'namey\\n2 reviews\\nFollow\\nDecember 21, 2025\\nfelt like a draft, boring plot, somewhat fun at times\\nyou get no description of what anything or anyone looks like or is like.\\nthe humor isnt anything special.\\nif it was longer it might have been better.\\ni plan to read the next volume anyway.\\nim bad at reviews\\nLike\\nComment'}\n",
      "{'username': '', 'date': '2025-12-21', 'text': \"Keila\\n182 reviews\\n4 followers\\nFollow\\nDecember 21, 2025\\nMy only peeve is that this book isn't any longer, but it put me off my miserable reading slump so I guess it's more than okay.\\ngn-beyond-outer-space\\n \\nshort-reads\\n2 likes\\nLike\\nComment\"}\n",
      "{'username': '', 'date': '2025-12-20', 'text': 'Lynda Kelly\\n116 reviews\\nFollow\\nDecember 20, 2025\\nIn my journey to find sci-fi I donâ€™t hate, this was alright. Quick and fun. Liked the narrator.\\nLike\\nComment'}\n",
      "{'username': '', 'date': '2025-12-20', 'text': 'Em\\n28 reviews\\nFollow\\nDecember 20, 2025\\nfirst few pages/chapters felt a bit slow (concerning for a novella??) but it picks up after and ended up being a fine read\\n1 like\\nLike\\nComment'}\n"
     ]
    }
   ],
   "source": [
    "path = \"reviews_newest.jsonl\"\n",
    "\n",
    "with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "    for i, line in enumerate(f):\n",
    "        review = json.loads(line)\n",
    "        print(review)\n",
    "        if i == 4:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5c3e50d1-e045-4576-9c94-ce8ca3d12f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'username': '', 'date': '2025-12-21', 'text': 'katy â™¡\\n186 reviews\\nFollow\\nDecember 21, 2025\\ni loved this. murderbot is just so cutie and funny. i just think bc itâ€™s soo short that i ended up confused a bit. i needed this to be longer with more explanations. i think thatâ€™s just a skill issue tho. i know thereâ€™s 7 more books, so i will absolutely be reading those at some point\\n3 likes\\nLike\\nComment'}\n",
      "{'username': '', 'date': '2025-12-21', 'text': 'namey\\n2 reviews\\nFollow\\nDecember 21, 2025\\nfelt like a draft, boring plot, somewhat fun at times\\nyou get no description of what anything or anyone looks like or is like.\\nthe humor isnt anything special.\\nif it was longer it might have been better.\\ni plan to read the next volume anyway.\\nim bad at reviews\\nLike\\nComment'}\n",
      "{'username': '', 'date': '2025-12-21', 'text': \"Keila\\n182 reviews\\n4 followers\\nFollow\\nDecember 21, 2025\\nMy only peeve is that this book isn't any longer, but it put me off my miserable reading slump so I guess it's more than okay.\\ngn-beyond-outer-space\\n \\nshort-reads\\n2 likes\\nLike\\nComment\"}\n",
      "{'username': '', 'date': '2025-12-20', 'text': 'Lynda Kelly\\n116 reviews\\nFollow\\nDecember 20, 2025\\nIn my journey to find sci-fi I donâ€™t hate, this was alright. Quick and fun. Liked the narrator.\\nLike\\nComment'}\n",
      "{'username': '', 'date': '2025-12-20', 'text': 'Em\\n28 reviews\\nFollow\\nDecember 20, 2025\\nfirst few pages/chapters felt a bit slow (concerning for a novella??) but it picks up after and ended up being a fine read\\n1 like\\nLike\\nComment'}\n"
     ]
    }
   ],
   "source": [
    "path = \"./seems-good/reviews_newest_1000ish.jsonl\"\n",
    "\n",
    "with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "    for i, line in enumerate(f):\n",
    "        review = json.loads(line)\n",
    "        print(review)\n",
    "        if i == 4:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6b23e3aa-3e9c-41e2-8a1b-1020a73843d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming reviews_oldest.jsonl with 0 reviews already saved\n",
      "\n",
      "ðŸš¨ MANUAL STEP ðŸš¨\n",
      "1) In the browser, set sort to the desired mode (Newest OR Oldest).\n",
      "2) Wait until the visible reviews reorder.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ðŸ‘‰ Press Enter to start automated scraping... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current URL after your sort: https://www.goodreads.com/book/show/32758901-all-systems-red/reviews\n",
      "Batch 1: saved 31 (total saved: 31)\n",
      "Batch 2: saved 30 (total saved: 61)\n",
      "Batch 3: saved 30 (total saved: 91)\n",
      "Batch 4: saved 30 (total saved: 121)\n",
      "Batch 5: saved 30 (total saved: 151)\n",
      "Batch 6: saved 30 (total saved: 181)\n",
      "Batch 7: saved 30 (total saved: 211)\n",
      "Batch 8: saved 30 (total saved: 241)\n",
      "Batch 9: saved 30 (total saved: 271)\n",
      "Batch 10: saved 30 (total saved: 301)\n",
      "Batch 11: saved 30 (total saved: 331)\n",
      "Batch 12: saved 30 (total saved: 361)\n",
      "Batch 13: saved 30 (total saved: 391)\n",
      "Batch 14: saved 30 (total saved: 421)\n",
      "Batch 15: saved 30 (total saved: 451)\n",
      "Batch 16: saved 30 (total saved: 481)\n",
      "Batch 17: saved 30 (total saved: 511)\n",
      "Batch 18: saved 30 (total saved: 541)\n",
      "Batch 19: saved 30 (total saved: 571)\n",
      "Batch 20: saved 30 (total saved: 601)\n",
      "Batch 21: saved 30 (total saved: 631)\n",
      "Batch 22: saved 30 (total saved: 661)\n",
      "Batch 23: saved 30 (total saved: 691)\n",
      "Batch 24: saved 30 (total saved: 721)\n",
      "Batch 25: saved 30 (total saved: 751)\n",
      "Batch 26: saved 30 (total saved: 781)\n",
      "Batch 27: saved 30 (total saved: 811)\n",
      "Batch 28: saved 30 (total saved: 841)\n",
      "Batch 29: saved 30 (total saved: 871)\n",
      "Batch 30: saved 30 (total saved: 901)\n",
      "Batch 31: saved 30 (total saved: 931)\n",
      "Batch 32: saved 30 (total saved: 961)\n",
      "Batch 33: saved 30 (total saved: 991)\n",
      "Batch 34: saved 30 (total saved: 1021)\n",
      "Batch 35: saved 30 (total saved: 1051)\n",
      "Batch 36: saved 30 (total saved: 1081)\n",
      "Batch 37: saved 30 (total saved: 1111)\n",
      "Batch 38: saved 30 (total saved: 1141)\n",
      "Batch 39: saved 30 (total saved: 1171)\n",
      "Batch 40: saved 30 (total saved: 1201)\n",
      "Batch 41: saved 30 (total saved: 1231)\n",
      "Batch 42: saved 30 (total saved: 1261)\n",
      "Batch 43: saved 30 (total saved: 1291)\n",
      "Batch 44: saved 30 (total saved: 1321)\n",
      "Batch 45: saved 30 (total saved: 1351)\n",
      "Batch 46: saved 30 (total saved: 1381)\n",
      "Batch 47: saved 30 (total saved: 1411)\n",
      "Batch 48: saved 30 (total saved: 1441)\n",
      "Batch 49: saved 30 (total saved: 1471)\n",
      "Batch 50: saved 30 (total saved: 1501)\n",
      "Batch 51: saved 30 (total saved: 1531)\n",
      "Batch 52: saved 30 (total saved: 1561)\n",
      "Batch 53: saved 30 (total saved: 1591)\n",
      "Batch 54: saved 30 (total saved: 1621)\n",
      "Batch 55: saved 30 (total saved: 1651)\n",
      "Batch 56: saved 30 (total saved: 1681)\n",
      "Batch 57: saved 30 (total saved: 1711)\n",
      "Batch 58: saved 30 (total saved: 1741)\n",
      "Batch 59: saved 30 (total saved: 1771)\n",
      "Batch 60: saved 30 (total saved: 1801)\n",
      "Batch 61: saved 30 (total saved: 1831)\n",
      "Batch 62: saved 30 (total saved: 1861)\n",
      "Batch 63: saved 30 (total saved: 1891)\n",
      "Batch 64: saved 29 (total saved: 1920)\n",
      "Batch 65: saved 30 (total saved: 1950)\n",
      "Batch 66: saved 30 (total saved: 1980)\n",
      "Batch 67: saved 30 (total saved: 2010)\n",
      "Batch 68: saved 30 (total saved: 2040)\n",
      "Page content did not change (hit window cap / end). Stopping.\n"
     ]
    }
   ],
   "source": [
    "# choose oldest, click show more, click enter.\n",
    "await scrape_after_manual_sort(\"reviews_oldest.jsonl\", max_batches=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a8ed0637-9d66-48c8-abd3-d970ec4dd8b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'username': '', 'date': '2024-02-22', 'text': 'Jessica\\n200 reviews\\n6 followers\\nFollow\\nFebruary 22, 2024\\nA great read -- an interesting concept well-executed and an exciting plot, too. I do love a (slightly) unreliable narrator. I really hope this will be a series!\\nfavorites\\n \\nfiction\\n \\nscience-fiction\\n1 like\\nLike\\nComment'}\n",
      "{'username': '', 'date': '2017-05-03', 'text': 'Silea\\n227 reviews\\n14 followers\\nFollow\\nMay 3, 2017\\nFast, fun, snarky. Eagerly awaiting Murderbot Diaries #2.\\nfiction\\nLike\\nComment'}\n",
      "{'username': '', 'date': '2017-05-03', 'text': \"Esteefee\\nAuthor\\xa0\\n3 books\\n6 followers\\nFollow\\nMay 3, 2017\\nMurderbot is so incredibly endearing -- I didn't stop grinning the entire time I was reading this novel. The Murderbot's social awkwardness with humans, its reliance on media rather than its own subpar training modules, its grim understanding of its own social standing, and of course the bumbling humans who want so desperately to help it. And all of this embedded in a fast-paced mystery/action/sci-fi adventure that had me so on edge I barely put it down, reading the book in two giant swallows.\\n\\nNow I shall have to re-read at a slower pace and savor.\\n1 like\\nLike\\nComment\"}\n",
      "{'username': '', 'date': '2018-09-02', 'text': 'Ginger\\n51 reviews\\nFollow\\nSeptember 2, 2018\\nvery satisfying but not nearly long enough! I have lots of new thoughts to think on, and I enjoyed the entire book.\\nLike\\nComment'}\n",
      "{'username': '', 'date': '2017-05-03', 'text': 'Garrison Nelson\\n53 reviews\\n3 followers\\nFollow\\nMay 3, 2017\\nMurderbot aint too shabby!\\n\\nI truly enjoyed this story. A brief but fun glimpse into a maniacally compassionate killing machine, honestly what more could you ask for? I highly recommend.\\nLike\\nComment'}\n"
     ]
    }
   ],
   "source": [
    "path = \"reviews_oldest.jsonl\"\n",
    "\n",
    "with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "    for i, line in enumerate(f):\n",
    "        review = json.loads(line)\n",
    "        print(review)\n",
    "        if i == 4:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6170d248-bbc9-4eb2-8049-b0519886ec40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3058555a-dbaf-4ddf-a54c-dc2426ac9f20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
